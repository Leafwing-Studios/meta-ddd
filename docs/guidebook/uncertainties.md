# Key Uncertainties
- Who actually reviews the pull request? The Keeper? The Sage? The Scribe?
- What is the exact framework for test documentation?
- Issue tracking structure needs to be fleshed out
- Examples for team structure section?
- How can we make it more clear that the DDD teams are autonomous and don't need or have traditional management oversight?
- How can we communicate that traditional management structures are usually a lot of overhead for little benefit, and that we fix that problem?
- There are definitely brass jobs without roles that should probably be defined
- We have the Quartermaster, which role is the battlemaster equivalent?
- Explicit information on automating away overhead. 
  - For example, if you automate testing and data analysis tools, and open them to the team, you don't need the overhead of data scientists and manager approval to run these tests (only to spit out reports that most people don't even understand). 
  - Stitch fix did this and have useful docs
    - [Multi-Armed Bandits - generalization of A/B testing for reinforcement learning](https://multithreaded.stitchfix.com/blog/2020/08/05/bandits/)
    - [Automated Experiment API](https://multithreaded.stitchfix.com/blog/2019/07/30/building-centralized-experimental-platform/)
- Use transparency to remove the need for recursive "whip-cracking" behavior. (Many companies do this to ensure Work Is Done:tm:.) How to make this clear?
  - VCS contains the past, key uncertainties contain the future
  - Issue tracking contains things that need to be done, but do not require discussion or debate. This includes both things that are already discussed, but need to be finished out, and things that are so small an simple to not merit discussion at all (like tiny bug fixes)
- Does DDD require aftercare? What would the aftercare format look like?
- What is the expected audience we are writing this guide for? Other software engineers? Business people? Laypeople?
- It would be good to have a whole section on automation: it's importance, the general philosophy behind it, how to do it, etc.
- Somewhere we need to make clear that a **project** contains one or more **teams** which contain several **crew members** and other roles
- In a multi-team project, which team is responsible for guidebook updates that affect everyone (such as changes to the code style guide)
  - Handled at the check-in?
  - Handled by the highest team?
  - Proposed, then must be accepted by all teams?
  - Anyone can modify at any time?
- Who conducts code review for subassemblies coming into the larger branch/master?
  - No one?
  - The higher team?

## Metadata Uncertainties

- Should key uncertainties have UUIDs for reference in external systems? How would we go about this scalably?
- We need a "I have a piece of information, where does it go?" section. Perhaps the is/ought divide is a useful divider here?
  - Documentation contains "is" statements. What is this system, how does it work, how would it work if things were different?
  - Guidebook contains "ought" statements. What do we want this to be? What goals are we trying to fulfil? What things are we unwilling to accept?
  - The test documentation contains tests and failures. While the documentation and guidebook primarily contain the "what", the test documentation contains the "why" (and sometimes "how"). Why did this system not work? Why do we have X technical constraint in our guidebook? 
- What is the exact structure of the guidebook?
  - How distributed is it?
    - Assimilation is starting to use a {key uncertainties, constraints, desired properties} system for its distributed guidebook. What should we steal from this, and how?
      - Should we add "tolerances" to this little framework?
  - In addition to the checklists and FAQ, what exactly does it hold?
  - How is system metadata stored?
    - Desired properties
    - Required properties
    - Constraints
    - Tolerances
    - Goals
    - Uncertainties by system?
  - Should we split "desired properties" into "required properties" and "desired properties", or are "required properties" better fit under constraints?
  - Desired properties:
    - Metadata for individual systems
    - **Guides:** lists of stuff, similar to what we use for static analysis. This includes things like code best practice, but also things like the fop balance guidelines (4:1 health:essence, essence/turn = prof, etc.)
    - Sections for less structured information (FAQs, meeting minutes, discussion logs, role assignments)
